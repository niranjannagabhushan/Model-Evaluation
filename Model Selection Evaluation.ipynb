{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is publically available from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The classification goal is to predict whether the patient has 10-year risk of future coronary heart disease (CHD).The dataset provides the patients’ information. It includes over 4,000 records and 16 attributes.\n",
    "#### Variables : <br>\n",
    "\n",
    "##### Demographic: <br>\n",
    "sex: male or female <br>\n",
    "age: age of the patient <br>\n",
    "\n",
    "##### Behavioural: <br>\n",
    "currentSmoker: whether or not the patient is a current smoker <br>\n",
    "cigsPerDay: the number of cigarettes that the person smoked on average in one day.<br>\n",
    "\n",
    "##### Medical history:<br>\n",
    "BPMeds: whether or not the patient was on blood pressure medication <br>\n",
    "prevalentStroke: whether or not the patient had previously had a stroke <br>\n",
    "prevalentHyp: whether or not the patient was hypertensive <br>\n",
    "diabetes: whether or not the patient had diabetes <br>\n",
    "\n",
    "##### Medical current:<br>\n",
    "totChol: total cholesterol level <br>\n",
    "sysBP: systolic blood pressure <br>\n",
    "diaBP: diastolic blood pressure <br>\n",
    "BMI: Body Mass Index <br>\n",
    "heartRate: heart rate <br>\n",
    "glucose: glucose level <br>\n",
    "\n",
    "##### Predict variable (desired target):<br>\n",
    "10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(r'data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['education'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'male':'Gender_male'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in df.isnull().sum(axis=1):\n",
    "    if i>0:\n",
    "        count=count+1\n",
    "print('Total number of rows with missing values is ', count)\n",
    "print('since it is only',round((count/len(df.index))*100), 'percent of the entire dataset the rows with missing values are excluded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_histograms(dataframe, features, rows, cols):\n",
    "    fig=plt.figure(figsize=(20,20))\n",
    "    for i, feature in enumerate(features):\n",
    "        ax=fig.add_subplot(rows,cols,i+1)\n",
    "        dataframe[feature].hist(bins=20,ax=ax,facecolor='midnightblue')\n",
    "        ax.set_title(feature+\" Distribution\",color='DarkRed')\n",
    "        \n",
    "    fig.tight_layout()  \n",
    "    plt.show()\n",
    "\n",
    "draw_histograms(df,df.columns,6,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TenYearCHD.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3179 patents with no heart disease and 572 patients with risk of heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(x='TenYearCHD',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data to train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features=df[['age','Gender_male','cigsPerDay','totChol','sysBP','glucose','TenYearCHD']]\n",
    "x=new_features.iloc[:,:-1]\n",
    "y=new_features.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True positives (TP): People who had heart disease and were also predicted to have heart disease. i.e 5 <br>\n",
    "True negatives (TN): People who did not have heart disease and were also predicted to not have heart disease. i.e 652 <br>\n",
    "False positives (FP): People who did not have heart disease but the prediction says they do.(Also known as a “Type I error.”) i.e 7 <br>\n",
    "False negatives (FN): People who have heart disease but the prediction says they don’t.(Also known as a “Type II error.”) i.e 87 <br>\n",
    "\n",
    "Sensitivity/Recall = TP/(TP + FN). When it’s actually yes, how often does it predict yes?<br>\n",
    "Specificity = TN/(TN + FP).When it’s actually no, how often does it predict no?<br>\n",
    "Precision = TP/predicted yes. When it predicts yes, how often is it correct?<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN=cm[0,0]\n",
    "TP=cm[1,1]\n",
    "FN=cm[1,0]\n",
    "FP=cm[0,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The acuuracy of the model = TP+TN/(TP+TN+FP+FN) = ',(TP+TN)/float(TP+TN+FP+FN),'\\n',\n",
    "\n",
    "'The Missclassification = 1-Accuracy = ',1-((TP+TN)/float(TP+TN+FP+FN)),'\\n',\n",
    "\n",
    "'Sensitivity or True Positive Rate = TP/(TP+FN) = ',TP/float(TP+FN),'\\n',\n",
    "\n",
    "'Specificity or True Negative Rate = TN/(TN+FP) = ',TN/float(TN+FP),'\\n',\n",
    "\n",
    "'Positive Predictive value = TP/(TP+FP) = ',TP/float(TP+FP),'\\n',\n",
    "\n",
    "'Negative predictive Value = TN/(TN+FN) = ',TN/float(TN+FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "for i in range(1,5):\n",
    "    cm2=0\n",
    "    y_pred_prob_yes=logreg.predict_proba(x_test)\n",
    "    y_pred2=binarize(y_pred_prob_yes,i/10)[:,1]\n",
    "    cm2=confusion_matrix(y_test,y_pred2)\n",
    "    print ('With',i/10,'threshold the Confusion Matrix is ','\\n',cm2,'\\n',\n",
    "            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n",
    "          'Sensitivity: ',cm2[1,1]/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### High Threshold: <br>\n",
    "High specificity <br>\n",
    "Low sensitivity <br>\n",
    "\n",
    "##### Low Threshold <br>\n",
    "Low specificity <br>\n",
    "High sensitivity <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob_yes[:,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for Heart disease classifier')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('True positive rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.roc_auc_score(y_test,y_pred_prob_yes[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area under the ROC curve quantifies model classification accuracy; higher the area, greater the disparity between true and false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast to GridSearchCV,In RandomizedSearchCV not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters ={\n",
    "                'tol' : [1e-5, 1e-4, 1e-3], # stopping criteria.\n",
    "                'class_weight' : [None, 'balanced'], # upsampling minority classs\n",
    "                'max_iter' : [100,150,200,250,300], # number of iterations\n",
    "                 'solver' : ['newton-cg', 'lbfgs'], # optimizer\n",
    "                'C':[1,2,3,4,5,6,7,8,9,10], # regularization parameter\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rs = RandomizedSearchCV(logreg, parameters, n_iter=10, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_rs.cv_results_).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model_rs.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update the data to oversample the minority class to have 70 percent the number of examples of the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.7,random_state=2)\n",
    "steps = [('o', over)] # oversampling\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_res, y_res = pipeline.fit_resample(x_train, y_train)\n",
    "\n",
    "\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rs.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model_rs.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions:\n",
    "Selected attributes are significant in the Heart disease prediction as their Pvalues lower than 5% <br>\n",
    "The trained model is more specific than sensitive. <br>\n",
    "The Area under the ROC curve is somewhat satisfactory. <br>\n",
    "Overall model could be improved with more data and complex model. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
